# -*- coding: utf-8 -*-
"""09_nn_hw.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1pDLkPBKslC36Tfdant1bH0HKrDqlr0y8

# <center> **Assignment 09** </center>
## <center> **Neural networks** </center>
## <center> **Benedek Dank√≥** </center>

#### 1 - 2. Implement fully connected neural network via using only numpy
"""

# Commented out IPython magic to ensure Python compatibility.
# %tensorflow_version 2.x

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import matplotlib.pyplot as plt
from google.colab import drive
from tensorflow import keras
from sklearn.metrics import accuracy_score
from sklearn.metrics import confusion_matrix
import seaborn as sn
import pandas as pd


# %matplotlib inline

weights = np.load('weights.npy', allow_pickle=True)

(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()
x_test = x_test.reshape(10000, 28*28)/255

def pred_nn(weights, inputs):
    layer1 = (weights[0].T@inputs.T + weights[1][None].T).clip(0,)
    layer2 = (weights[2].T@layer1 + weights[3][None].T).clip(0,)
    layer3 = (weights[4].T@layer2 + weights[5][None].T).clip(0,)
    layer4 = weights[6].T@layer3 + weights[7][None].T
    return (np.exp(layer4)/np.exp(layer4).sum(0)).T

x_test[:3].shape, pred_nn(weights, x_test[:3]).shape

"""#### 3. Same architecture via tensorflow/keras"""

# Create model, add weights manually:
model = keras.Sequential()
model.add(keras.layers.Dense(750, activation='relu', input_dim=784))
model.add(keras.layers.Dense(500, activation='relu'))
model.add(keras.layers.Dense(500, activation='relu'))
model.add(keras.layers.Dense(10, activation='softmax'))
model.add_weight(shape=weights[0].shape)
model.add_weight(shape=weights[2].shape)
model.add_weight(shape=weights[4].shape)
model.add_weight(shape=weights[6].shape)

model.summary()

"""#### 4-5. Compare performances"""

# split data, scale data, convert it:
(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()
x_test = x_test.reshape(10000, 28*28)/255
x_train = x_train.reshape(60000, 28*28)/255
y_train_oh = keras.utils.to_categorical(y_train)
y_test_oh = keras.utils.to_categorical(y_test)
print(x_test.shape, x_train.shape)

# compile, fit data to model:
model.compile(loss='categorical_crossentropy', optimizer=keras.optimizers.SGD(lr=1e-2), metrics=['accuracy'])
history = model.fit(x=x_train, y=y_train_oh, batch_size=64, epochs=15, validation_data=(x_test, y_test_oh))

# Commented out IPython magic to ensure Python compatibility.
# %%time
# np_preds = pred_nn(weights, x_test)

# Commented out IPython magic to ensure Python compatibility.
# %%time
# tf_preds = model.predict(x_test)

cce = keras.losses.CategoricalCrossentropy()
cce(y_test_oh, tf_preds).numpy()

"""Accuracy: 0.9789, categorical crossentropy: 0.0911 for the tensorflow model. 
Unluckily, my manually created NN model does not really works, there are some issues druing back propagation.
"""

# create confusion matrix:
cm = confusion_matrix(y_pred=np.argmax(np_preds, 1), y_true=y_test)

cm

df_cm = pd.DataFrame(cm)
plt.figure(figsize = (10,7))
sn.heatmap(df_cm, cmap='mako', vmax=30)
plt.title("Confusion matrix - My NN model", fontsize=16)
plt.xlabel('Predicted label')
plt.ylabel('Actual label')
plt.show()

"""Number 4 and 9 can be changed up in some case, or values 3 and 8, or values 5 and 3 as well."""